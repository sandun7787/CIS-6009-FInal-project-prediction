{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ad45a7ce-7bcd-4ee8-accd-a62aa660635b",
   "metadata": {},
   "source": [
    "# Heart Disease Prediction Sytsem Using Machin Learning\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0bab4f65-d578-444f-8744-4319ddacce83",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import os\n",
    "import tarfile\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.feature_selection import  RFE, SelectFromModel\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import accuracy_score\n",
    "import matplotlib.pyplot as plt\n",
    "from six.moves import urllib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a75fd682-93fa-40f2-b3b9-360874523135",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load heart data from CSV file into a DataFrame called 'heart_data'\n",
    "heart_data = pd.read_csv('heart.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7d513689-022a-415a-add7-fb3a2753b3c3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>cp</th>\n",
       "      <th>trestbps</th>\n",
       "      <th>chol</th>\n",
       "      <th>fbs</th>\n",
       "      <th>restecg</th>\n",
       "      <th>thalach</th>\n",
       "      <th>exang</th>\n",
       "      <th>oldpeak</th>\n",
       "      <th>slope</th>\n",
       "      <th>ca</th>\n",
       "      <th>thal</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>52</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>125</td>\n",
       "      <td>212</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>168</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>53</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>140</td>\n",
       "      <td>203</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>155</td>\n",
       "      <td>1</td>\n",
       "      <td>3.1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>70</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>145</td>\n",
       "      <td>174</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>125</td>\n",
       "      <td>1</td>\n",
       "      <td>2.6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>61</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>148</td>\n",
       "      <td>203</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>161</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>62</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>138</td>\n",
       "      <td>294</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>106</td>\n",
       "      <td>0</td>\n",
       "      <td>1.9</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>58</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>100</td>\n",
       "      <td>248</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>122</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>58</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>114</td>\n",
       "      <td>318</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>140</td>\n",
       "      <td>0</td>\n",
       "      <td>4.4</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>55</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>160</td>\n",
       "      <td>289</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>145</td>\n",
       "      <td>1</td>\n",
       "      <td>0.8</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>46</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>120</td>\n",
       "      <td>249</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>144</td>\n",
       "      <td>0</td>\n",
       "      <td>0.8</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>54</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>122</td>\n",
       "      <td>286</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>116</td>\n",
       "      <td>1</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   age  sex  cp  trestbps  chol  fbs  restecg  thalach  exang  oldpeak  slope  \\\n",
       "0   52    1   0       125   212    0        1      168      0      1.0      2   \n",
       "1   53    1   0       140   203    1        0      155      1      3.1      0   \n",
       "2   70    1   0       145   174    0        1      125      1      2.6      0   \n",
       "3   61    1   0       148   203    0        1      161      0      0.0      2   \n",
       "4   62    0   0       138   294    1        1      106      0      1.9      1   \n",
       "5   58    0   0       100   248    0        0      122      0      1.0      1   \n",
       "6   58    1   0       114   318    0        2      140      0      4.4      0   \n",
       "7   55    1   0       160   289    0        0      145      1      0.8      1   \n",
       "8   46    1   0       120   249    0        0      144      0      0.8      2   \n",
       "9   54    1   0       122   286    0        0      116      1      3.2      1   \n",
       "\n",
       "   ca  thal  target  \n",
       "0   2     3       0  \n",
       "1   0     3       0  \n",
       "2   0     3       0  \n",
       "3   1     3       0  \n",
       "4   3     2       0  \n",
       "5   0     2       1  \n",
       "6   3     1       0  \n",
       "7   1     3       0  \n",
       "8   0     3       0  \n",
       "9   2     2       0  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "heart_data.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5ea9df1c-444a-4616-94e0-2a8fdfe0005f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1025 entries, 0 to 1024\n",
      "Data columns (total 14 columns):\n",
      " #   Column    Non-Null Count  Dtype  \n",
      "---  ------    --------------  -----  \n",
      " 0   age       1025 non-null   int64  \n",
      " 1   sex       1025 non-null   int64  \n",
      " 2   cp        1025 non-null   int64  \n",
      " 3   trestbps  1025 non-null   int64  \n",
      " 4   chol      1025 non-null   int64  \n",
      " 5   fbs       1025 non-null   int64  \n",
      " 6   restecg   1025 non-null   int64  \n",
      " 7   thalach   1025 non-null   int64  \n",
      " 8   exang     1025 non-null   int64  \n",
      " 9   oldpeak   1025 non-null   float64\n",
      " 10  slope     1025 non-null   int64  \n",
      " 11  ca        1025 non-null   int64  \n",
      " 12  thal      1025 non-null   int64  \n",
      " 13  target    1025 non-null   int64  \n",
      "dtypes: float64(1), int64(13)\n",
      "memory usage: 112.2 KB\n"
     ]
    }
   ],
   "source": [
    "# get more information about the data set\n",
    "heart_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5a3a15ad-8824-4128-824b-4a7728086b4b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>cp</th>\n",
       "      <th>trestbps</th>\n",
       "      <th>chol</th>\n",
       "      <th>fbs</th>\n",
       "      <th>restecg</th>\n",
       "      <th>thalach</th>\n",
       "      <th>exang</th>\n",
       "      <th>oldpeak</th>\n",
       "      <th>slope</th>\n",
       "      <th>ca</th>\n",
       "      <th>thal</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1025.000000</td>\n",
       "      <td>1025.000000</td>\n",
       "      <td>1025.000000</td>\n",
       "      <td>1025.000000</td>\n",
       "      <td>1025.00000</td>\n",
       "      <td>1025.000000</td>\n",
       "      <td>1025.000000</td>\n",
       "      <td>1025.000000</td>\n",
       "      <td>1025.000000</td>\n",
       "      <td>1025.000000</td>\n",
       "      <td>1025.000000</td>\n",
       "      <td>1025.000000</td>\n",
       "      <td>1025.000000</td>\n",
       "      <td>1025.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>54.434146</td>\n",
       "      <td>0.695610</td>\n",
       "      <td>0.942439</td>\n",
       "      <td>131.611707</td>\n",
       "      <td>246.00000</td>\n",
       "      <td>0.149268</td>\n",
       "      <td>0.529756</td>\n",
       "      <td>149.114146</td>\n",
       "      <td>0.336585</td>\n",
       "      <td>1.071512</td>\n",
       "      <td>1.385366</td>\n",
       "      <td>0.754146</td>\n",
       "      <td>2.323902</td>\n",
       "      <td>0.513171</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>9.072290</td>\n",
       "      <td>0.460373</td>\n",
       "      <td>1.029641</td>\n",
       "      <td>17.516718</td>\n",
       "      <td>51.59251</td>\n",
       "      <td>0.356527</td>\n",
       "      <td>0.527878</td>\n",
       "      <td>23.005724</td>\n",
       "      <td>0.472772</td>\n",
       "      <td>1.175053</td>\n",
       "      <td>0.617755</td>\n",
       "      <td>1.030798</td>\n",
       "      <td>0.620660</td>\n",
       "      <td>0.500070</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>29.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>94.000000</td>\n",
       "      <td>126.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>71.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>48.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>120.000000</td>\n",
       "      <td>211.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>132.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>56.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>130.000000</td>\n",
       "      <td>240.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>152.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>61.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>140.000000</td>\n",
       "      <td>275.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>166.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.800000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>77.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>200.000000</td>\n",
       "      <td>564.00000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>202.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>6.200000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               age          sex           cp     trestbps        chol  \\\n",
       "count  1025.000000  1025.000000  1025.000000  1025.000000  1025.00000   \n",
       "mean     54.434146     0.695610     0.942439   131.611707   246.00000   \n",
       "std       9.072290     0.460373     1.029641    17.516718    51.59251   \n",
       "min      29.000000     0.000000     0.000000    94.000000   126.00000   \n",
       "25%      48.000000     0.000000     0.000000   120.000000   211.00000   \n",
       "50%      56.000000     1.000000     1.000000   130.000000   240.00000   \n",
       "75%      61.000000     1.000000     2.000000   140.000000   275.00000   \n",
       "max      77.000000     1.000000     3.000000   200.000000   564.00000   \n",
       "\n",
       "               fbs      restecg      thalach        exang      oldpeak  \\\n",
       "count  1025.000000  1025.000000  1025.000000  1025.000000  1025.000000   \n",
       "mean      0.149268     0.529756   149.114146     0.336585     1.071512   \n",
       "std       0.356527     0.527878    23.005724     0.472772     1.175053   \n",
       "min       0.000000     0.000000    71.000000     0.000000     0.000000   \n",
       "25%       0.000000     0.000000   132.000000     0.000000     0.000000   \n",
       "50%       0.000000     1.000000   152.000000     0.000000     0.800000   \n",
       "75%       0.000000     1.000000   166.000000     1.000000     1.800000   \n",
       "max       1.000000     2.000000   202.000000     1.000000     6.200000   \n",
       "\n",
       "             slope           ca         thal       target  \n",
       "count  1025.000000  1025.000000  1025.000000  1025.000000  \n",
       "mean      1.385366     0.754146     2.323902     0.513171  \n",
       "std       0.617755     1.030798     0.620660     0.500070  \n",
       "min       0.000000     0.000000     0.000000     0.000000  \n",
       "25%       1.000000     0.000000     2.000000     0.000000  \n",
       "50%       1.000000     0.000000     2.000000     1.000000  \n",
       "75%       2.000000     1.000000     3.000000     1.000000  \n",
       "max       2.000000     4.000000     3.000000     1.000000  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Count: Number of non-null observations in each column.\n",
    "# Mean: Average value of each column, indicating the central tendency.\n",
    "# Std: Standard deviation, a measure of the dispersion or spread of values around the mean.\n",
    "# Min: Minimum value observed in each column.\n",
    "# 25%: First quartile, or the value below which 25% of the data falls.\n",
    "# 50%: Median, or the middle value of the dataset.\n",
    "# 75%: Third quartile, or the value below which 75% of the data falls.\n",
    "# Max: Maximum value observed in each column.\n",
    "heart_data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "90869faf-27b1-44f3-99b4-9d3cb59102fb",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'X' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[9], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m X_train, X_test, Y_train, Y_test \u001b[38;5;241m=\u001b[39m train_test_split(\u001b[43mX\u001b[49m, Y, test_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.2\u001b[39m, stratify\u001b[38;5;241m=\u001b[39mY, random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m42\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'X' is not defined"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7db08d62-778f-439c-82bf-380b0bc14dfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %matplotlib inline: Display plots inline in Jupyter Notebook.\n",
    "import matplotlib.pyplot as plt  # Import the matplotlib library.\n",
    "heart_data.hist(bins=50, figsize=(20,10))  # Generate histograms for each numerical column.\n",
    "plt.show()  # Show the histograms."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79456478-3891-4a2b-9651-bc24841a8f86",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrieve the shape of the 'heart_data' DataFrame\n",
    "heart_data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bdede55-aea9-4a5f-a735-98229b67f9ad",
   "metadata": {},
   "source": [
    "# Explotary Data Anlysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbf98bdc-9ca3-40e7-81d3-9be66ce2137e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This line of code appears to be using the .isnull() method on the 'heart_data' DataFrame to check for missing values, \n",
    "heart_data.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a45e2f7-1c59-406b-b4a6-a93541b5e365",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Correlation between other attribute"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f32b433-99b7-449e-b04e-66329ebc44fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "corr_metrix=heart_data.corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfb2e537-656f-4244-8a92-5f4f298c51db",
   "metadata": {},
   "outputs": [],
   "source": [
    "corr_metrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbdc4fe1-aa26-4c1f-8e41-b323a3340511",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Assuming heart_data is your DataFrame\n",
    "# Calculate correlation matrix\n",
    "correlation_matrix = heart_data.corr()\n",
    "\n",
    "# Set up the figure with two subplots\n",
    "fig, axes = plt.subplots(1, 2, figsize=(16, 6))\n",
    "\n",
    "# Plotting the correlation matrix as a heatmap\n",
    "sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', fmt=\".2f\", ax=axes[0])\n",
    "axes[0].set_title('Correlation Matrix')\n",
    "\n",
    "# Pie plot for distribution of target variable (assuming it's named 'target')\n",
    "heart_data['target'].value_counts().plot.pie(autopct='%1.1f%%', ax=axes[1], labels=['No Disease', 'Disease'])\n",
    "axes[1].set_title('Distribution of Target Variable')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0800356-2605-4cc1-a4e8-e31c6428732e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Summary Statistics\n",
    "print(heart_data.describe())\n",
    "\n",
    "# Histograms for numerical features\n",
    "heart_data.hist(figsize=(12, 10))\n",
    "plt.suptitle('Histograms of Numerical Features')\n",
    "plt.show()\n",
    "\n",
    "# Boxplots for numerical features\n",
    "plt.figure(figsize=(12, 10))\n",
    "sns.boxplot(data=heart_data)\n",
    "plt.title('Boxplots of Numerical Features')\n",
    "plt.show()\n",
    "\n",
    "# Correlation Matrix\n",
    "correlation_matrix = heart_data.corr()\n",
    "plt.figure(figsize=(12, 10))\n",
    "sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', fmt=\".2f\")\n",
    "plt.title('Correlation Matrix')\n",
    "plt.show()\n",
    "\n",
    "# Pairplot for selected features with scatterplot\n",
    "selected_features = ['age', 'sex', 'cp', 'trestbps', 'chol', 'fbs', 'thalach', 'exang', 'oldpeak', 'slope', 'ca', 'thal', 'target']\n",
    "sns.pairplot(heart_data[selected_features], kind='scatter')\n",
    "plt.title('Pairplot of Selected Features with Scatterplot')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3f49cf4-d6bd-4961-b935-a7515f14ec29",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Generate descriptive statistics\n",
    "description = heart_data.describe()\n",
    "\n",
    "# Plotting the bar chart\n",
    "plt.figure(figsize=(10, 6))\n",
    "description.plot(kind='bar')\n",
    "plt.title('Descriptive Statistics')\n",
    "plt.ylabel('Value')\n",
    "plt.xlabel('Statistic')\n",
    "plt.grid(True)\n",
    "plt.legend(loc='upper right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c223c53-f48f-4fc6-b7ce-b9bdc94a9cae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This line of code is using the value_counts() method on the 'target' column of the 'heart_data' DataFrame.\n",
    "# It counts the occurrences of each unique value in the 'target' column and returns a Series object \n",
    "# with the counts of each unique value.\n",
    "heart_data['target'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00eefa8b-7a06-4691-926a-60dbc5332cb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assigning input features to variable X by dropping the 'target' column from the 'heart_data' DataFrame\n",
    "# axis=1 specifies that we are dropping a column\n",
    "X = heart_data.drop(columns='target', axis=1)\n",
    "\n",
    "# Assigning the target variable to variable Y\n",
    "Y = heart_data['target']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9241b63-cf04-48fe-9e66-d13b2c873fb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Printing the input features (X) DataFrame\n",
    "print(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8d486e86-b1c9-46e6-8d4c-363b8bca3090",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'X' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[7], line 11\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodel_selection\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m train_test_split\n\u001b[0;32m      3\u001b[0m \u001b[38;5;66;03m# Splitting the data into training and testing sets for both input features (X) and target variable (Y)\u001b[39;00m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;66;03m# X_train: Training input features\u001b[39;00m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;66;03m# X_test: Testing input features\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[38;5;66;03m# stratify=Y: Ensures that the distribution of classes in the target variable Y is preserved in both the training and testing sets\u001b[39;00m\n\u001b[0;32m     10\u001b[0m \u001b[38;5;66;03m# random_state=2: Provides a seed for random number generation to ensure reproducibility of the split\u001b[39;00m\n\u001b[1;32m---> 11\u001b[0m X_train, X_test, Y_train, Y_test \u001b[38;5;241m=\u001b[39m train_test_split(\u001b[43mX\u001b[49m, Y, test_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.2\u001b[39m, stratify\u001b[38;5;241m=\u001b[39mY, random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m42\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'X' is not defined"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Splitting the data into training and testing sets for both input features (X) and target variable (Y)\n",
    "# X_train: Training input features\n",
    "# X_test: Testing input features\n",
    "# Y_train: Training target variable\n",
    "# Y_test: Testing target variable\n",
    "# test_size=0.2: Specifies that 20% of the data will be used for testing, and the rest will be used for training\n",
    "# stratify=Y: Ensures that the distribution of classes in the target variable Y is preserved in both the training and testing sets\n",
    "# random_state=2: Provides a seed for random number generation to ensure reproducibility of the split\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2, stratify=Y, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f8aaa53-bf2e-48b7-bd18-85f9565d35bc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3cdeaff7-42d6-448b-81b6-6904be2b8286",
   "metadata": {},
   "source": [
    "# Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c6c287e-745f-4896-9c8c-24befa96c30a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# Logistic Regression\n",
    "model = LogisticRegression()  # Initialize Logistic Regression model\n",
    "model.fit(X_train, Y_train)  # Train Logistic Regression model\n",
    "Y_pred_logreg = model.predict(X_test)  # Predict using Logistic Regression model\n",
    "logreg_accuracy = accuracy_score(Y_test, Y_pred_logreg)  # Calculate accuracy of Logistic Regression model\n",
    "logreg_mse = mean_squared_error(Y_test, Y_pred_logreg)  # Calculate MSE of Logistic Regression model\n",
    "logreg_rmse = np.sqrt(logreg_mse)  # Calculate RMSE of Logistic Regression model\n",
    "print(\"Logistic Regression Accuracy:\", logreg_accuracy)  # Print accuracy of Logistic Regression model\n",
    "print(\"Logistic Regression Mean Squared Error (MSE):\", logreg_mse)  # Print MSE of Logistic Regression model\n",
    "print(\"Logistic Regression Root Mean Squared Error (RMSE):\", logreg_rmse)  # Print RMSE of Logistic Regression model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6391b495-f35b-407a-83fb-0cac7cfc4bb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predicting the target values for the training data using the trained model.\n",
    "X_train_prediction = model.predict(X_train)\n",
    "\n",
    "# Calculating the accuracy of the model's predictions on the training data.\n",
    "# This is done by comparing the predicted values (X_train_prediction) with the actual target values (Y_train).\n",
    "training_data_accuracy = accuracy_score(X_train_prediction, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba93fb5c-18a4-4fa6-b655-f1f5e431e48c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Printing the accuracy of the model's predictions on the training data.\n",
    "# This provides a measure of how well the model is performing on the data it was trained on.\n",
    "print('Accuracy on Training data : ', training_data_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a391b41-0fbf-45e4-9711-9b4dc77e8bf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predicting the target values for the test data using the trained model.\n",
    "X_test_prediction = model.predict(X_test)\n",
    "\n",
    "# Calculating the accuracy of the model's predictions on the test data.\n",
    "# This is done by comparing the predicted values (X_test_prediction) with the actual target values (Y_test).\n",
    "test_data_accuracy = accuracy_score(X_test_prediction, Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62961e44-c480-4c8b-b1e0-490c10317e34",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Printing the accuracy of the model's predictions on the test data.\n",
    "# This provides insight into how well the model generalizes to unseen data, giving an indication of its performance in real-world scenarios.\n",
    "print('Accuracy on Test data : ', test_data_accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "523bcd57-3343-4b47-9ef5-ab0d7ee861b3",
   "metadata": {},
   "source": [
    "# Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c268463-3a03-489d-a6ad-b6aaf04388a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, mean_squared_error\n",
    "import numpy as np\n",
    "\n",
    "# Random Forest Classifier\n",
    "model2 = RandomForestClassifier(n_estimators=200, max_depth=50, min_samples_split=400, random_state=42)\n",
    "model2.fit(X_train, Y_train)\n",
    "rf_test_pred = model2.predict(X_test)\n",
    "rf_test_accuracy = accuracy_score(Y_test, rf_test_pred)\n",
    "rf_mse = mean_squared_error(Y_test, rf_test_pred)\n",
    "rf_rmse = np.sqrt(rf_mse)\n",
    "\n",
    "# Print Random Forest Results\n",
    "print(\"Random Forest validation accuracy:\", rf_test_accuracy)\n",
    "print(f\"Random Forest Mean Squared Error (MSE): {rf_mse:.4f}\")\n",
    "print(f\"Random Forest Root Mean Squared Error (RMSE): {rf_rmse:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa0bf60e-b2d6-4cfe-83e2-7641dfa5bf3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Predicting the target values for the training data using the trained model.\n",
    "X_train_prediction = model2.predict(X_train)\n",
    "\n",
    "# Calculating the accuracy of the model's predictions on the training data.\n",
    "# This is done by comparing the predicted values (X_train_prediction) with the actual target values (Y_train).\n",
    "training_data_accuracy = accuracy_score(X_train_prediction, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54af25b6-b1fe-4464-9b88-e1f1b64d9a38",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predicting the target values for the test data using the trained model.\n",
    "X_test_prediction = model2.predict(X_test)\n",
    "\n",
    "# Calculating the accuracy of the model's predictions on the test data.\n",
    "# This is done by comparing the predicted values (X_test_prediction) with the actual target values (Y_test).\n",
    "test_data_accuracy = accuracy_score(X_test_prediction, Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f57582b7-060e-452f-bbc1-d01078191163",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Printing the accuracy of the model's predictions on the training data.\n",
    "# This provides a measure of how well the model is performing on the data it was trained on.\n",
    "print('Accuracy on Training data : ', training_data_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f375d41-6c66-408d-9d38-34d45a97de92",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Printing the accuracy of the model's predictions on the test data.\n",
    "# This provides insight into how well the model generalizes to unseen data, giving an indication of its performance in real-world scenarios.\n",
    "print('Accuracy on Test data : ', test_data_accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95bd4930-5482-4c5d-952c-721f8640d4dd",
   "metadata": {},
   "source": [
    "# Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6737f30-63d6-4bea-8bfb-7aabf53b6184",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score, mean_squared_error\n",
    "import numpy as np\n",
    "\n",
    "# Decision Tree Classifier\n",
    "model3 = DecisionTreeClassifier(max_depth=50, min_samples_split=400, random_state=42)\n",
    "model3.fit(X_train, Y_train)\n",
    "dt_test_pred = model3.predict(X_test)\n",
    "dt_test_accuracy = accuracy_score(Y_test, dt_test_pred)\n",
    "dt_mse = mean_squared_error(Y_test, dt_test_pred)\n",
    "dt_rmse = np.sqrt(dt_mse)\n",
    "\n",
    "# Print Decision Tree Results\n",
    "print(\"Decision Tree validation accuracy:\", dt_test_accuracy)\n",
    "print(f\"Decision Tree Mean Squared Error (MSE): {dt_mse:.4f}\")\n",
    "print(f\"Decision Tree Root Mean Squared Error (RMSE): {dt_rmse:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cee8133b-f8c2-46b1-a04f-2355dcbd70f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predicting the target values for the training data using the trained model.\n",
    "X_train_prediction = model3.predict(X_train)\n",
    "\n",
    "# Calculating the accuracy of the model's predictions on the training data.\n",
    "# This is done by comparing the predicted values (X_train_prediction) with the actual target values (Y_train).\n",
    "training_data_accuracy = accuracy_score(X_train_prediction, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0091eb79-f208-4156-8260-e830b98d907b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Printing the accuracy of the model's predictions on the training data.\n",
    "# This provides a measure of how well the model is performing on the data it was trained on.\n",
    "print('Accuracy on Training data : ', training_data_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20c4e8f7-6421-4f04-8b36-55e6e69927b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predicting the target values for the test data using the trained model.\n",
    "X_test_prediction = model3.predict(X_test)\n",
    "\n",
    "# Calculating the accuracy of the model's predictions on the test data.\n",
    "# This is done by comparing the predicted values (X_test_prediction) with the actual target values (Y_test).\n",
    "test_data_accuracy = accuracy_score(X_test_prediction, Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cd13cd6-24c1-47bd-99a7-5447ec44178c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Printing the accuracy of the model's predictions on the test data.\n",
    "# This provides insight into how well the model generalizes to unseen data, giving an indication of its performance in real-world scenarios.\n",
    "print('Accuracy on Test data : ', test_data_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4731b18-0c0f-43f9-b8c2-0bfc5d452dff",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# Logistic Regression\n",
    "model1 = LogisticRegression()\n",
    "lr_cv_scores = cross_val_score(model1, X, Y, cv=5)  # 5-fold cross-validation\n",
    "lr_mean_accuracy = lr_cv_scores.mean()\n",
    "\n",
    "# Decision Tree\n",
    "model2 = DecisionTreeClassifier(max_depth=50, min_samples_split=400, random_state=42)\n",
    "dt_cv_scores = cross_val_score(model2, X, Y, cv=5)  # 5-fold cross-validation\n",
    "dt_mean_accuracy = dt_cv_scores.mean()\n",
    "\n",
    "# Random Forest\n",
    "model3 = RandomForestClassifier(n_estimators=200, max_depth=50, min_samples_split=400, random_state=42)\n",
    "rf_cv_scores = cross_val_score(model3, X, Y, cv=5)  # 5-fold cross-validation\n",
    "rf_mean_accuracy = rf_cv_scores.mean()\n",
    "\n",
    "# Print Cross-Validation Results in the correct order\n",
    "print(\"Logistic Regression Cross-Validation Mean Accuracy:\", lr_mean_accuracy)\n",
    "print(\"Decision Tree Cross-Validation Mean Accuracy:\", dt_mean_accuracy)\n",
    "print(\"Random Forest Cross-Validation Mean Accuracy:\", rf_mean_accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06277ad1-27e9-425d-8ede-4271ab460ba8",
   "metadata": {},
   "source": [
    "# Hyper Parameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ceedffb-9554-419d-868a-cbaf30234b44",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score, GridSearchCV\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# Logistic Regression Hyperparameter Tuning\n",
    "lr_param_grid = {'C': [0.001, 0.01, 0.1, 1, 10, 100]}  # Define hyperparameter grid\n",
    "lr_model = LogisticRegression()  # Define logistic regression model\n",
    "lr_grid_search = GridSearchCV(model, lr_param_grid, cv=5)  # Perform grid search with 5-fold cross-validation\n",
    "lr_grid_search.fit(X_train, Y_train)  # Fit grid search on training data\n",
    "best_lr_model = lr_grid_search.best_estimator_  # Get best logistic regression model\n",
    "best_lr_params = lr_grid_search.best_params_  # Get best parameters\n",
    "lr_accuracy = best_lr_model.score(X_test, Y_test)  # Evaluate best model on test data\n",
    "\n",
    "# Decision Tree Hyperparameter Tuning\n",
    "dt_param_grid = {'max_depth': [10, 20, 30, 40, 50], 'min_samples_split': [100, 200, 300, 400, 500]}  # Define hyperparameter grid\n",
    "dt_model = DecisionTreeClassifier(random_state=42)  # Define decision tree model\n",
    "dt_grid_search = GridSearchCV(model2, dt_param_grid, cv=5)  # Perform grid search with 5-fold cross-validation\n",
    "dt_grid_search.fit(X_train, Y_train)  # Fit grid search on training data\n",
    "best_dt_model = dt_grid_search.best_estimator_  # Get best decision tree model\n",
    "best_dt_params = dt_grid_search.best_params_  # Get best parameters\n",
    "dt_accuracy = best_dt_model.score(X_test, Y_test)  # Evaluate best model on test data\n",
    "\n",
    "# Random Forest Hyperparameter Tuning\n",
    "rf_param_grid = {'n_estimators': [100, 200, 300], 'max_depth': [10, 20, 30, 40, 50], 'min_samples_split': [100, 200, 300, 400, 500]}  # Define hyperparameter grid\n",
    "rf_model = RandomForestClassifier(random_state=42)  # Define random forest model\n",
    "rf_grid_search = GridSearchCV(model3, rf_param_grid, cv=5)  # Perform grid search with 5-fold cross-validation\n",
    "rf_grid_search.fit(X_train, Y_train)  # Fit grid search on training data\n",
    "best_rf_model = rf_grid_search.best_estimator_  # Get best random forest model\n",
    "best_rf_params = rf_grid_search.best_params_  # Get best parameters\n",
    "rf_accuracy = best_rf_model.score(X_test, Y_test)  # Evaluate best model on test data\n",
    "\n",
    "# Print Hyperparameter Tuning Results\n",
    "print(\"Logistic Regression Best Parameters:\", best_lr_params)\n",
    "print(\"Logistic Regression Test Accuracy with Best Parameters:\", lr_accuracy)\n",
    "print(\"Decision Tree Best Parameters:\", best_dt_params)\n",
    "print(\"Decision Tree Test Accuracy with Best Parameters:\", dt_accuracy)\n",
    "print(\"Random Forest Best Parameters:\", best_rf_params)\n",
    "print(\"Random Forest Test Accuracy with Best Parameters:\", rf_accuracy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a55f0e4c-ef1b-4410-9c34-6efa5c7a9206",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, classification_report, confusion_matrix\n",
    "# Logistic Regression Hyperparameter Tuning\n",
    "lr_param_grid = {'C': [0.001, 0.01, 0.1, 1, 10, 100]}  # Define hyperparameter grid\n",
    "lr_model = LogisticRegression()  # Define logistic regression model\n",
    "lr_grid_search = GridSearchCV(lr_model, lr_param_grid, cv=5)  # Perform grid search with 5-fold cross-validation\n",
    "lr_grid_search.fit(X_train, Y_train)  # Fit grid search on training data\n",
    "best_lr_model = lr_grid_search.best_estimator_  # Get best logistic regression model\n",
    "best_lr_params = lr_grid_search.best_params_  # Get best parameters\n",
    "lr_predictions = best_lr_model.predict(X_test)  # Predictions on test data\n",
    "lr_accuracy = best_lr_model.score(X_test, Y_test)  # Accuracy score\n",
    "lr_precision = precision_score(Y_test, lr_predictions)  # Precision score\n",
    "lr_recall = recall_score(Y_test, lr_predictions)  # Recall score\n",
    "lr_f1 = f1_score(Y_test, lr_predictions)  # F1-score\n",
    "\n",
    "# Decision Tree Hyperparameter Tuning\n",
    "dt_param_grid = {'max_depth': [10, 20, 30, 40, 50], 'min_samples_split': [100, 200, 300, 400, 500]}  # Define hyperparameter grid\n",
    "dt_model = DecisionTreeClassifier(random_state=42)  # Define decision tree model\n",
    "dt_grid_search = GridSearchCV(dt_model, dt_param_grid, cv=5)  # Perform grid search with 5-fold cross-validation\n",
    "dt_grid_search.fit(X_train, Y_train)  # Fit grid search on training data\n",
    "best_dt_model = dt_grid_search.best_estimator_  # Get best decision tree model\n",
    "best_dt_params = dt_grid_search.best_params_  # Get best parameters\n",
    "dt_predictions = best_dt_model.predict(X_test)  # Predictions on test data\n",
    "dt_accuracy = best_dt_model.score(X_test, Y_test)  # Accuracy score\n",
    "dt_precision = precision_score(Y_test, dt_predictions)  # Precision score\n",
    "dt_recall = recall_score(Y_test, dt_predictions)  # Recall score\n",
    "dt_f1 = f1_score(Y_test, dt_predictions)  # F1-score\n",
    "\n",
    "# Random Forest Hyperparameter Tuning\n",
    "rf_param_grid = {'n_estimators': [100, 200, 300], 'max_depth': [10, 20, 30, 40, 50], 'min_samples_split': [100, 200, 300, 400, 500]}  # Define hyperparameter grid\n",
    "rf_model = RandomForestClassifier(random_state=42)  # Define random forest model\n",
    "rf_grid_search = GridSearchCV(rf_model, rf_param_grid, cv=5)  # Perform grid search with 5-fold cross-validation\n",
    "rf_grid_search.fit(X_train, Y_train)  # Fit grid search on training data\n",
    "best_rf_model = rf_grid_search.best_estimator_  # Get best random forest model\n",
    "best_rf_params = rf_grid_search.best_params_  # Get best parameters\n",
    "rf_predictions = best_rf_model.predict(X_test)  # Predictions on test data\n",
    "rf_accuracy = best_rf_model.score(X_test, Y_test)  # Accuracy score\n",
    "rf_precision = precision_score(Y_test, rf_predictions)  # Precision score\n",
    "rf_recall = recall_score(Y_test, rf_predictions)  # Recall score\n",
    "rf_f1 = f1_score(Y_test, rf_predictions)  # F1-score\n",
    "\n",
    "# Print Hyperparameter Tuning Results\n",
    "print(\"Logistic Regression Best Parameters:\", best_lr_params)\n",
    "print(\"Logistic Regression Test Metrics with Best Parameters:\")\n",
    "print(\"  Accuracy:\", lr_accuracy)\n",
    "print(\"  Precision:\", lr_precision)\n",
    "print(\"  Recall:\", lr_recall)\n",
    "print(\"  F1-score:\", lr_f1)\n",
    "\n",
    "print(\"\\nDecision Tree Best Parameters:\", best_dt_params)\n",
    "print(\"Decision Tree Test Metrics with Best Parameters:\")\n",
    "print(\"  Accuracy:\", dt_accuracy)\n",
    "print(\"  Precision:\", dt_precision)\n",
    "print(\"  Recall:\", dt_recall)\n",
    "print(\"  F1-score:\", dt_f1)\n",
    "\n",
    "print(\"\\nRandom Forest Best Parameters:\", best_rf_params)\n",
    "print(\"Random Forest Test Metrics with Best Parameters:\")\n",
    "print(\"  Accuracy:\", rf_accuracy)\n",
    "print(\"  Precision:\", rf_precision)\n",
    "print(\"  Recall:\", rf_recall)\n",
    "print(\"  F1-score:\", rf_f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5f81050-1da4-4053-8a39-335b2136a982",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_data = (58\t,0\t,0\t,100,\t248,\t0,\t0,\t122\t,0,\t1,\t1,\t0\t,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91b38396-0618-4b65-89e2-0e98acf7e1d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Assuming 'input_data' is your input data and 'model3' is your trained DecisionTreeClassifier model\n",
    "\n",
    "# Convert input data to numpy array\n",
    "input_data_as_numpy_array = np.asarray(input_data)\n",
    "\n",
    "# Reshape input data\n",
    "input_data_reshaped = input_data_as_numpy_array.reshape(1, -1)\n",
    "\n",
    "# Check if model is fitted\n",
    "if hasattr(model, 'fit'):\n",
    "    # Fit the model\n",
    "    model.fit(X_train, Y_train)\n",
    "    \n",
    "    # Make predictions\n",
    "    prediction = model.predict(input_data_reshaped)\n",
    "    \n",
    "    # Print prediction\n",
    "    print(prediction)\n",
    "    \n",
    "    # Check prediction and print result\n",
    "    if prediction[0] == 0:\n",
    "        print('The Person does not have a Heart Disease')\n",
    "    else:\n",
    "        print('The Person has Heart Disease')\n",
    "else:\n",
    "    print(\"Error: Model has not been fitted.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e32516c4-9970-4fb6-b623-3d036de729f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\t\n",
    "62,\t66\t,0,\t2,\t146,\t278\t,0\t,0,\t152,\t0\t,0\t,1,\t1,\t2"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
